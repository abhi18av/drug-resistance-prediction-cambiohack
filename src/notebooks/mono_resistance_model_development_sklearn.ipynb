{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "NOTE NB-models don't give us feature_importances_\n",
    "https://stackoverflow.com/questions/41592661/determining-the-most-contributing-features-for-svm-classifier-in-sklearn\n",
    "\n",
    "NOTE we can include ELI5 for explanation of predictors\n",
    "https://github.com/TeamHG-Memex/eli5\n",
    "\n",
    "NOTE There are other explanation oriented libraries as well\n",
    "https://github.com/DistrictDataLabs/yellowbrick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the usual suspects.\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "\n",
    "\n",
    "\n",
    "def print_ln():\n",
    "    print('-' * 80, '\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_performance_metrics(model, X, X_test, X_train, y, y_test, y_pred, detailed= False, show_feature_importances= True):\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print_ln()\n",
    "    \n",
    "\n",
    "    if show_feature_importances:\n",
    "\n",
    "        feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                               index =  X_train.columns,\n",
    "                                               columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"=== Feature Importances ===\")\n",
    "        print(feature_importances)\n",
    "\n",
    "\n",
    "    \n",
    "    if detailed:\n",
    "        model_score = cross_val_score(model, X, y, cv=10)\n",
    "\n",
    "\n",
    "        print(\"=== Confusion Matrix ===\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print_ln()\n",
    "\n",
    "        print(\"=== Classification Report ===\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print_ln()\n",
    "\n",
    "        print(\"=== All AUC Scores ===\")\n",
    "        print(model_score)\n",
    "\n",
    "        print_ln()\n",
    "\n",
    "        print(\"=== Mean AUC Score ===\")\n",
    "        print(model_score.mean())\n",
    "        print_ln()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            NC000962_3.78  NC000962_3.80  NC000962_3.102  NC000962_3.104  \\\nSampleID                                                                   \nERR3129939              0              0               0               0   \nERR3148148              0              0               0               0   \nERR3148149              0              0               0               0   \nERR3148151              0              0               0               0   \nERR3148153              0              0               0               0   \n\n            NC000962_3.117  NC000962_3.120  NC000962_3.135  NC000962_3.138  \\\nSampleID                                                                     \nERR3129939               0               0               0               0   \nERR3148148               0               0               0               0   \nERR3148149               0               0               0               0   \nERR3148151               0               0               0               0   \nERR3148153               0               0               0               0   \n\n            NC000962_3.150  NC000962_3.155  ...  NC000962_3.4409994  \\\nSampleID                                    ...                       \nERR3129939               0               0  ...                   0   \nERR3148148               0               0  ...                   0   \nERR3148149               0               0  ...                   0   \nERR3148151               0               0  ...                   0   \nERR3148153               0               0  ...                   0   \n\n            NC000962_3.4410001  NC000962_3.4410033  NC000962_3.4410043  \\\nSampleID                                                                 \nERR3129939                   0                   0                   0   \nERR3148148                   0                   0                   0   \nERR3148149                   0                   0                   0   \nERR3148151                   0                   0                   0   \nERR3148153                   0                   0                   0   \n\n            NC000962_3.4410061  NC000962_3.4410065  NC000962_3.4410066  \\\nSampleID                                                                 \nERR3129939                   0                   0                   0   \nERR3148148                   0                   0                   0   \nERR3148149                   0                   0                   0   \nERR3148151                   0                   0                   0   \nERR3148153                   0                   0                   0   \n\n            NC000962_3.4410070  NC000962_3.4411245  isResistant  \nSampleID                                                         \nERR3129939                   0                   0            0  \nERR3148148                   0                   0            0  \nERR3148149                   0                   0            1  \nERR3148151                   0                   0            1  \nERR3148153                   0                   0            0  \n\n[5 rows x 118669 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NC000962_3.78</th>\n      <th>NC000962_3.80</th>\n      <th>NC000962_3.102</th>\n      <th>NC000962_3.104</th>\n      <th>NC000962_3.117</th>\n      <th>NC000962_3.120</th>\n      <th>NC000962_3.135</th>\n      <th>NC000962_3.138</th>\n      <th>NC000962_3.150</th>\n      <th>NC000962_3.155</th>\n      <th>...</th>\n      <th>NC000962_3.4409994</th>\n      <th>NC000962_3.4410001</th>\n      <th>NC000962_3.4410033</th>\n      <th>NC000962_3.4410043</th>\n      <th>NC000962_3.4410061</th>\n      <th>NC000962_3.4410065</th>\n      <th>NC000962_3.4410066</th>\n      <th>NC000962_3.4410070</th>\n      <th>NC000962_3.4411245</th>\n      <th>isResistant</th>\n    </tr>\n    <tr>\n      <th>SampleID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ERR3129939</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ERR3148148</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ERR3148149</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>ERR3148151</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>ERR3148153</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 118669 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mono_resistance_df_filledna = pd.read_csv(\"../data/processed/mono_resistance_df_filledna.csv\").set_index('SampleID')\n",
    "\n",
    "mono_resistance_df_filledna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mono_resistance_df_filledna.loc[:, mono_resistance_df_filledna.columns != 'isResistant']\n",
    "y = mono_resistance_df_filledna.loc[:, 'isResistant']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8021978021978022\n",
      "Mean Absolute Error: 0.1978021978021978\n",
      "Mean Squared Error: 0.1978021978021978\n",
      "Root Mean Squared Error: 0.4447495899966607\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "=== Feature Importances ===\n",
      "                    importance\n",
      "NC000962_3.3478244      0.1875\n",
      "NC000962_3.1480184      0.1250\n",
      "NC000962_3.1480945      0.0625\n",
      "NC000962_3.3478245      0.0625\n",
      "NC000962_3.3843572      0.0625\n",
      "...                        ...\n",
      "NC000962_3.1398290      0.0000\n",
      "NC000962_3.1398287      0.0000\n",
      "NC000962_3.1398271      0.0000\n",
      "NC000962_3.1398251      0.0000\n",
      "NC000962_3.4411245      0.0000\n",
      "\n",
      "[118668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "model_rf= RandomForestClassifier(n_estimators= 100,\n",
    "                                  random_state = 100,\n",
    "                                  max_depth=5,\n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=50)\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model_rf.predict(X_test)\n",
    "\n",
    "model_performance_metrics(model_rf, X, X_test, X_train, y, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7692307692307693\n",
      "Mean Absolute Error: 0.23076923076923078\n",
      "Mean Squared Error: 0.23076923076923078\n",
      "Root Mean Squared Error: 0.4803844614152614\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "=== Feature Importances ===\n",
      "                    importance\n",
      "NC000962_3.1637145    0.057574\n",
      "NC000962_3.3750587    0.040738\n",
      "NC000962_3.3735813    0.039937\n",
      "NC000962_3.1637035    0.039575\n",
      "NC000962_3.3941568    0.031643\n",
      "...                        ...\n",
      "NC000962_3.1400440    0.000000\n",
      "NC000962_3.1400437    0.000000\n",
      "NC000962_3.1400436    0.000000\n",
      "NC000962_3.1400423    0.000000\n",
      "NC000962_3.4411245    0.000000\n",
      "\n",
      "[118668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model_gb= GradientBoostingClassifier(\n",
    "                                     n_estimators= 100,\n",
    "                                     random_state = 100,\n",
    "                                     max_depth=5\n",
    "                                    )\n",
    "\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model_gb.predict(X_test)\n",
    "\n",
    "\n",
    "model_performance_metrics(model_gb, X, X_test, X_train, y, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6593406593406593\n",
      "Mean Absolute Error: 0.34065934065934067\n",
      "Mean Squared Error: 0.34065934065934067\n",
      "Root Mean Squared Error: 0.5836602955995385\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model_nb= GaussianNB()\n",
    "# model_nb= BernoulliNB()\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model_nb.predict(X_test)\n",
    "\n",
    "\n",
    "model_performance_metrics(model_nb, X, X_test, X_train, y, y_test, y_pred, show_feature_importances= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7472527472527473\n",
      "Mean Absolute Error: 0.25274725274725274\n",
      "Mean Squared Error: 0.25274725274725274\n",
      "Root Mean Squared Error: 0.5027397465361703\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_mlp = MLPClassifier(\n",
    "                          solver='lbfgs', \n",
    "                          alpha=1e-5,\n",
    "                          hidden_layer_sizes=(5, 2), \n",
    "                          random_state=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model_mlp.predict(X_test)\n",
    "\n",
    "model_performance_metrics(model_mlp, X, X_test, X_train, y, y_test, y_pred, show_feature_importances= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7912087912087912\n",
      "Mean Absolute Error: 0.2087912087912088\n",
      "Mean Squared Error: 0.2087912087912088\n",
      "Root Mean Squared Error: 0.4569367667316877\n",
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "=== Feature Importances ===\n",
      "                    importance\n",
      "NC000962_3.841353     0.056812\n",
      "NC000962_3.104941     0.047203\n",
      "NC000962_3.1637145    0.037451\n",
      "NC000962_3.333008     0.035202\n",
      "NC000962_3.1573220    0.034451\n",
      "...                        ...\n",
      "NC000962_3.1400077    0.000000\n",
      "NC000962_3.1400074    0.000000\n",
      "NC000962_3.1400072    0.000000\n",
      "NC000962_3.1399635    0.000000\n",
      "NC000962_3.4411245    0.000000\n",
      "\n",
      "[118668 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(\n",
    "                          learning_rate= 0.01, \n",
    "                          random_state= 1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= model_xgb.predict(X_test)\n",
    "\n",
    "model_performance_metrics(model_xgb, X, X_test, X_train, y, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7582417582417582\n",
      "Mean Absolute Error: 0.24175824175824176\n",
      "Mean Squared Error: 0.24175824175824176\n",
      "Root Mean Squared Error: 0.4916891718944416\n",
      "-------------------------------------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StackingClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-6b0f9c9df1a8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_se\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m \u001B[0mmodel_performance_metrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_se\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-14-2cc755f7e8f4>\u001B[0m in \u001B[0;36mmodel_performance_metrics\u001B[1;34m(model, X, X_test, X_train, y, y_test, y_pred, detailed, show_feature_importances)\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mshow_feature_importances\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m         feature_importances = pd.DataFrame(model.feature_importances_,\n\u001B[0m\u001B[0;32m     13\u001B[0m                                                \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m  \u001B[0mX_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                                                columns=['importance']).sort_values('importance', ascending=False)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'StackingClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier()),\n",
    "    ('svc', LinearSVC()),\n",
    "    ('mlp', MLPClassifier()),\n",
    "    ('nb', GaussianNB()),\n",
    "    ('xgb', XGBClassifier())\n",
    "]\n",
    "\n",
    "model_se = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestClassifier()\n",
    ")\n",
    "\n",
    "model_se.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_se.predict(X_test)\n",
    "\n",
    "model_performance_metrics(model_se, X, X_test, X_train, y, y_test, y_pred, show_feature_importances= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (drug-resistance-prediction-cambiohack)",
   "language": "python",
   "name": "pycharm-f27e5417"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}